{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddd815a-89b4-432e-bc9d-99280239b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from sentiment2d import Sentiment2D\n",
    "\n",
    "# Create new `pandas` methods which use `tqdm` progress\n",
    "tqdm.pandas()\n",
    "\n",
    "def turn_to_utterance(df, speaker):\n",
    "    END_OF_UTTERANCE_PUNCTUATION = \".!?\"\n",
    "    end_of_line = \"$\"\n",
    "    regexp = f'([^{END_OF_UTTERANCE_PUNCTUATION}]+({end_of_line}|[{END_OF_UTTERANCE_PUNCTUATION}]))'\n",
    "    \n",
    "    # split into target speaker and all other speakers\n",
    "    idx = df['speaker'].isin([speaker])\n",
    "    odf = df[~idx].copy()\n",
    "    odf['sequence'] = df.index[~idx]\n",
    "    tdf = df[idx].copy()\n",
    "    tdf['sequence'] = df.index[idx]\n",
    "    tdf['Xline'] = tdf['line'].apply(lambda x: x.replace(\"...\", \"XXX\") if x else ' ')\n",
    "    odf['Xline'] = odf['line'].apply(lambda x: x.replace(\"...\", \"XXX\") if x else ' ')\n",
    "    \n",
    "    frags = []\n",
    "    for row in tdf.itertuples():\n",
    "        if (row.Index - 1) in odf.index:\n",
    "            preceeding_Xline_s = odf[odf.index == (row.Index - 1)]['Xline']\n",
    "            preceeding_Xline_v = preceeding_Xline_s.values\n",
    "            if len(preceeding_Xline_v) > 0:\n",
    "                preceeding_Xline = preceeding_Xline_v[0]\n",
    "        for m in re.findall(regexp, row.Xline.replace('\"', ' ')):\n",
    "            frags += [(m[0], row.sequence)]\n",
    "\n",
    "    # join any true fragments into full utterances\n",
    "    utterances = []\n",
    "    utt = ''\n",
    "    for f, s in frags:\n",
    "        utt += ' ' + f\n",
    "        if f[-1] in END_OF_UTTERANCE_PUNCTUATION:\n",
    "            utterances += [(utt.replace(\"XXX\", \"...\"), s, speaker)]\n",
    "            utt = ''\n",
    "    \n",
    "    return pd.DataFrame(utterances, columns=['utterance', 'sequence', 'speaker'])\n",
    "\n",
    "\n",
    "def session_sentiment_figure(df, annotations=None, labels=('Valence', 'Arousal'), \n",
    "                             title='', legend_x=0.48, legend_y=0.90):\n",
    "    '''\n",
    "    This figure is inspired by Russell's original work \n",
    "    --- A Circumplex Model of Affect ---\n",
    "    \n",
    "    :param df: Data Frame with one utterance per row and columns [speaker, utterance, valence, arousal]\n",
    "    '''\n",
    "    FONT_COLOR = '#666666'\n",
    "    FILL_COLOR = 'rgb(.7,.7,.7)'\n",
    "    COLORS = ['rgba(62,148,204,127)', 'rgba(213,134,58,127)', 'rgba(126,154,102,127)']\n",
    "    \n",
    "    utt_av = df.copy()\n",
    "    speakers = utt_av.speaker.unique().tolist()\n",
    "    utt_av['length'] = utt_av['utterance'].apply(lambda u: len(u.split()))\n",
    "    utt_av['weight'] = utt_av['length'] / utt_av['length'].sum()\n",
    "    \n",
    "    utt_av['utterance'] = utt_av['utterance'].str.wrap(30)\n",
    "    utt_av['utterance'] = utt_av['utterance'].apply(lambda x: x.replace('\\n', '<br>'))\n",
    "    \n",
    "    fig = px.scatter(utt_av,\n",
    "                     x=labels[0], y=labels[1],\n",
    "                     title=title,\n",
    "                     hover_data=['utterance'],\n",
    "                     size='weight',\n",
    "                     color='speaker',\n",
    "                     color_discrete_sequence=COLORS,\n",
    "                     opacity=0.5)\n",
    "    \n",
    "    for i, spk in enumerate(speakers):\n",
    "        idx = utt_av.speaker == spk\n",
    "        x_mn = (utt_av.loc[idx, labels[0]] * utt_av.loc[utt_av.speaker == spk, 'weight']).sum()\n",
    "        y_mn = (utt_av.loc[idx, labels[1]] * utt_av.loc[utt_av.speaker == spk, 'weight']).sum()\n",
    "        fig.add_annotation(x=x_mn, y=y_mn, text='<b>x<b>', showarrow=False, xanchor='center',\n",
    "                           font=dict(family=\"Arial Black\", size=30, color=COLORS[i % len(COLORS)]))\n",
    "\n",
    "    if annotations:\n",
    "        for w, coord in annotations.items():\n",
    "            align = 'left' if coord[0] < -0.5 else 'right' if coord[0] > 0.5 else 'center'\n",
    "            fig.add_annotation(x=coord[0], y=coord[1], text=w, showarrow=False, xanchor=align,\n",
    "                               font=dict(size=15, color='rgba(0,0,0,.6)'))\n",
    "        \n",
    "    fig.update_yaxes(range=[-1.05, 1.05],\n",
    "                     showgrid=False,\n",
    "                     zerolinecolor='rgba(.2,.2,.2,.2)',\n",
    "                     tickfont=dict(size=18, color=FONT_COLOR),\n",
    "                     title_font=dict(size=24, color=FONT_COLOR),\n",
    "                     tickvals=[-1, -0.5, 0.0, 0.5, 1])\n",
    "    \n",
    "    fig.update_xaxes(scaleanchor='x', \n",
    "                     scaleratio=1,\n",
    "                     range=[-1.05, 1.05],\n",
    "                     showgrid=False,\n",
    "                     zerolinecolor='rgba(.2,.2,.2,.2)',\n",
    "                     tickfont=dict(size=18, color=FONT_COLOR),\n",
    "                     title_font=dict(size=24, color=FONT_COLOR),\n",
    "                     tickvals=[-1, -0.5, 0.0, 0.5, 1])\n",
    "    \n",
    "    fig.add_shape(type='rect', xref='x', yref='y', fillcolor=FILL_COLOR, x0=-1.05, y0=-1.05, x1=1.05, y1=1.05, \n",
    "                  line_color=FILL_COLOR, opacity=0.1)\n",
    "    \n",
    "    fig.update_layout(plot_bgcolor='rgba(0,0,0,0)', showlegend=True, height=700, width=700, font=dict(size=16), \n",
    "                      legend=dict(yanchor='top', y=legend_y, xanchor='center', x=legend_x, \n",
    "                                  bgcolor='rgba(1,1,1,0)', title='', font=dict(size=15)))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aa4998-28da-4056-8b23-24807c23ebd3",
   "metadata": {},
   "source": [
    "## Parse the raw transcript into utterances\n",
    "\n",
    "Loads the raw therapy transcript and parses it into a dataframe where each row is a talk turn. Note that the transcript is adapted from a publicly available therapy session transcript from Carl Rogers' published [therapy session transcripts](https://anamartinspsicoterapiaacp.files.wordpress.com/2016/04/brodley-transcripts-of-carl-rogers-therapy-sessions.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d60bb08-8f00-438b-af3e-6a198e4b7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the turn-taking dataframe\n",
    "turn_df = pd.read_csv('./carl_and_gloria.csv')\n",
    "\n",
    "# parse into utterances\n",
    "utterance_df = pd.concat((turn_to_utterance(turn_df, 'Therapist'), turn_to_utterance(turn_df, 'Patient')))\n",
    "utterance_df = utterance_df.sort_values('sequence').reset_index(drop=True)\n",
    "utterance_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd3f5d-3429-42a6-9613-5089656c6259",
   "metadata": {},
   "source": [
    "## Run the sentiment model on utterances\n",
    "NOTE: the first time you run this the large language model will need to be downloaded. It will be cached locally, so after the first run it should be faster. However, depending on your system (e.g., no GPU acceleration), computing sentiment may still take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37825d17-6ab6-4cdd-9bb6-9c3fcdb19627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sentiment scores (may take a while!)\n",
    "s2d = Sentiment2D()\n",
    "valence, arousal = [], []\n",
    "for idx, row in enumerate(utterance_df.itertuples()):\n",
    "    v, a = s2d(row.utterance)\n",
    "    valence.append(v)\n",
    "    arousal.append(a)\n",
    "    print('.', end='', flush=True)\n",
    "    \n",
    "# If running on a GPU, the following may be more efficient:\n",
    "#valence, arousal = s2d(utterance_df.utterance.to_list())\n",
    "\n",
    "df = utterance_df.copy()\n",
    "df['Valence'] = valence\n",
    "df['Arousal'] = arousal\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e01007-43f1-457f-b04a-4ac29b7c2415",
   "metadata": {},
   "source": [
    "## Display the 2d sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f4f20-a035-4e15-a8ea-89e7b00f4c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 2D sentiment coordinates for some anchor words to annotate the plot\n",
    "anchor_words = ['excited', 'satisfied', 'relaxed', 'bored', 'depressed', \n",
    "                'annoyed', 'grounded', 'furious', 'sleepy', 'disgusted', \n",
    "                'upset', 'content', 'aroused', 'numb']\n",
    "v, a = s2d([f'I am feeling {word}' for word in anchor_words])\n",
    "annotations = {w: (v, a) for w, v, a in zip(anchor_words, v, a)}\n",
    "#annotations = {word: s2d([f'I am feeling {word}']) for word in anchor_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5ee4e-876b-42b2-a729-9a1f201ea81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = session_sentiment_figure(df, annotations, legend_y=1.01, legend_x=0.3)\n",
    "fig.write_image('./sentiment.png', scale=1.5)\n",
    "# To save an interactive version of the plot (note: this will be a large file!):\n",
    "#fig.write_html(\"./sentiment.html\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
